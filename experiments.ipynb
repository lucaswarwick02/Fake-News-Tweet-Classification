{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./dataset/mediaeval-2015-trainingset.txt', sep='\\t', index_col=None)\n",
    "test_df = pd.read_csv('./dataset/mediaeval-2015-testset.txt', sep='\\t', index_col=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "1901"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['tweetText'].duplicated().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate tweets before filter: 1901\n",
      "Number of duplicate tweets after filter: 1902\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer, TweetTokenizer\n",
    "\n",
    "print(f'Number of duplicate tweets before filter: {train_df[\"tweetText\"].duplicated().sum()}')\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_word(word: str) -> str:\n",
    "    if word[0] == '#':\n",
    "        return '#' + lemmatizer.lemmatize(word[1:])\n",
    "    else:\n",
    "        return lemmatizer.lemmatize(word)\n",
    "\n",
    "def filter_text(text: str) -> str:\n",
    "    # Before tokenization\n",
    "\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # After tokenization\n",
    "    tokens = [lemmatize_word(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "train_df['filteredTweetText'] = train_df['tweetText'].apply(lambda text: filter_text(text))\n",
    "print(f'Number of duplicate tweets after filter: {train_df[\"filteredTweetText\"].duplicated().sum()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "0     ¿Se acuerdan de la película: “El día después d...\n1     @milenagimon: Miren a Sandy en NY!  Tremenda i...\n2     Buena la foto del Huracán Sandy, me recuerda a...\n3        Scary shit #hurricane #NY http://t.co/e4JLBUfH\n4     My fave place in the world #nyc #hurricane #sa...\n5     42nd #time #square #NYC #subway #hurricane htt...\n6     Just in time for #halloween a photo of #hurric...\n7     Crazy pic of #Hurricane #Sandy prayers go out ...\n8     #sandy #newyork #hurricane #statueofliberty #U...\n9                  #nyc #hurricane http://t.co/Gv3QxZlq\n10    robertosalibaba  god be with u brother #sandy ...\n11        #Crazy #Hurricane #Sandy http://t.co/0zrMsgvs\n12    #shark #newjersey #swim #sandy #hurricane  ...\n13    Good luck #ny #newyork #usa #hurricane #sandy ...\n14    Wow.... Fishing anyone? #hurricane #sandy http...\nName: tweetText, dtype: object"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['tweetText'].head(15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import re\n",
    "def count_emojis(text: str) -> int:\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\"\n",
    "    \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    count = len(re.findall(emoji_pattern, text))\n",
    "    return count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def count_hashtags(text:str) -> int:\n",
    "    words = text.split(' ')\n",
    "    return len([word for word in words if word[0] == '#'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='char_wb', ngram_range=(5, 5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "model = MultinomialNB()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}