{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./dataset/mediaeval-2015-trainingset.txt', sep='\\t', index_col=None)\n",
    "test_df = pd.read_csv('./dataset/mediaeval-2015-testset.txt', sep='\\t', index_col=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from nltk import TweetTokenizer, WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "url_regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "emoji_regex = re.compile(\"[\"\n",
    "                         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                        u\"\\U00002702-\\U000027B0\"\n",
    "                        u\"\\U000024C2-\\U0001F251\"\n",
    "                         \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def count_emojis(text: str) -> int:\n",
    "    return len(re.findall(emoji_regex, text))\n",
    "\n",
    "def count_urls(text: str) -> int:\n",
    "    return len(re.findall(url_regex, text))\n",
    "\n",
    "def count_hashtags(text: str) -> int:\n",
    "    return len([word for word in tokenizer.tokenize(text) if word[0] == '#'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def filter_text(text: str) -> str:\n",
    "    text = re.sub(emoji_regex, '', text)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [lemmatize_word(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def lemmatize_word(word: str) -> str:\n",
    "    if word[0] == '#':\n",
    "        return '#' + lemmatizer.lemmatize(word[1:])\n",
    "    else:\n",
    "        return lemmatizer.lemmatize(word)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Extraction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_df['emojis'] = train_df['tweetText'].apply(lambda text: count_emojis(text))\n",
    "train_df['hashtags'] = train_df['tweetText'].apply(lambda text: count_hashtags(text))\n",
    "train_df['filteredTweetText'] = train_df['tweetText'].apply(lambda text: filter_text(text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "test_df['emojis'] = test_df['tweetText'].apply(lambda text: count_emojis(text))\n",
    "test_df['hashtags'] = test_df['tweetText'].apply(lambda text: count_hashtags(text))\n",
    "test_df['filteredTweetText'] = test_df['tweetText'].apply(lambda text: filter_text(text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "               tweetId                                          tweetText  \\\n0   263046056240115712  ¿Se acuerdan de la película: “El día después d...   \n1   262995061304852481  @milenagimon: Miren a Sandy en NY!  Tremenda i...   \n2   262979898002534400  Buena la foto del Huracán Sandy, me recuerda a...   \n3   262996108400271360     Scary shit #hurricane #NY http://t.co/e4JLBUfH   \n4   263018881839411200  My fave place in the world #nyc #hurricane #sa...   \n5   263364439582060545  42nd #time #square #NYC #subway #hurricane htt...   \n6   262927032705490944  Just in time for #halloween a photo of #hurric...   \n7   263321078884077568  Crazy pic of #Hurricane #Sandy prayers go out ...   \n8   263111677485142017  #sandy #newyork #hurricane #statueofliberty #U...   \n9   262977091983785985               #nyc #hurricane http://t.co/Gv3QxZlq   \n10  262989009930833920  robertosalibaba  god be with u brother #sandy ...   \n11  263129115207536640      #Crazy #Hurricane #Sandy http://t.co/0zrMsgvs   \n12  263091320871063552  #shark #newjersey #swim #sandy #hurricane  ...   \n13  262990978611286016  Good luck #ny #newyork #usa #hurricane #sandy ...   \n14  263070862977167360  Wow.... Fishing anyone? #hurricane #sandy http...   \n15  263270378221228033  Well #howdy there #hurricane #sandy . Just wan...   \n16  263229641999925249  Just known this bcs of #jason #chen updated th...   \n17  263184498072645632  My thoughts and prayers go to all of the peopl...   \n18  263001267926880258  Stay safe my New York family...#nyc #newyork #...   \n19  263363592508829697    New York #hurricane #Sandy http://t.co/AnrR8u7t   \n20  263058558160076801  Probably the coolest pic of #hurricanesandy! #...   \n21  263286294522777601  Crazy #sandy #hurricane images. Be glad we liv...   \n22  263010650517807104  My cousin sent this to me... :: Cleveland voic...   \n23  262976546527145984  We forget tomb unknown soldier is guard 24/736...   \n24  262971979282395136  “@DarcyPhilip #new #york #hurricane #sandy htt...   \n\n    emojis  hashtags                                  filteredTweetText  \n0        0         1  ¿ se acuerdan de la película : “ el día despué...  \n1        0         0  @milenagimon : miren a sandy en ny ! tremenda ...  \n2        0         2  buena la foto del huracán sandy , me recuerda ...  \n3        0         2     scary shit #hurricane #ny http://t.co/e4JLBUfH  \n4        1         4  my fave place in the world #nyc #hurricane #sa...  \n5        0         5  42nd #time #square #nyc #subway #hurricane htt...  \n6        0         4  just in time for #halloween a photo of #hurric...  \n7        0         2  crazy pic of #hurricane #sandy prayer go out t...  \n8        0         5  #sandy #newyork #hurricane #statueofliberty #u...  \n9        0         2               #nyc #hurricane http://t.co/Gv3QxZlq  \n10       0         3  robertosalibaba god be with u brother #sandy #...  \n11       0         3      #crazy #hurricane #sandy http://t.co/0zrMsgvs  \n12       1         5  #shark #newjersey #swim #sandy #hurricane http...  \n13       0         5  good luck #ny #newyork #usa #hurricane #sandy ...  \n14       0         2  wow ... fishing anyone ? #hurricane #sandy htt...  \n15       0         3  well #howdy there #hurricane #sandy . just wan...  \n16       0         7  just known this bcs of #jason #chen updated th...  \n17       0        10  my thought and prayer go to all of the people ...  \n18       0         5  stay safe my new york family ... #nyc #newyork...  \n19       0         2    new york #hurricane #sandy http://t.co/AnrR8u7t  \n20       0         6  probably the coolest pic of #hurricanesandy ! ...  \n21       0         3  crazy #sandy #hurricane image . be glad we liv...  \n22       1         3  my cousin sent this to me ... :: cleveland voi...  \n23       0         3  we forget tomb unknown soldier is guard 24/736...  \n24       0         4  “ @darcyphilip #new #york #hurricane #sandy ht...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweetId</th>\n      <th>tweetText</th>\n      <th>emojis</th>\n      <th>hashtags</th>\n      <th>filteredTweetText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>263046056240115712</td>\n      <td>¿Se acuerdan de la película: “El día después d...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>¿ se acuerdan de la película : “ el día despué...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>262995061304852481</td>\n      <td>@milenagimon: Miren a Sandy en NY!  Tremenda i...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>@milenagimon : miren a sandy en ny ! tremenda ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>262979898002534400</td>\n      <td>Buena la foto del Huracán Sandy, me recuerda a...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>buena la foto del huracán sandy , me recuerda ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>262996108400271360</td>\n      <td>Scary shit #hurricane #NY http://t.co/e4JLBUfH</td>\n      <td>0</td>\n      <td>2</td>\n      <td>scary shit #hurricane #ny http://t.co/e4JLBUfH</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>263018881839411200</td>\n      <td>My fave place in the world #nyc #hurricane #sa...</td>\n      <td>1</td>\n      <td>4</td>\n      <td>my fave place in the world #nyc #hurricane #sa...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>263364439582060545</td>\n      <td>42nd #time #square #NYC #subway #hurricane htt...</td>\n      <td>0</td>\n      <td>5</td>\n      <td>42nd #time #square #nyc #subway #hurricane htt...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>262927032705490944</td>\n      <td>Just in time for #halloween a photo of #hurric...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>just in time for #halloween a photo of #hurric...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>263321078884077568</td>\n      <td>Crazy pic of #Hurricane #Sandy prayers go out ...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>crazy pic of #hurricane #sandy prayer go out t...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>263111677485142017</td>\n      <td>#sandy #newyork #hurricane #statueofliberty #U...</td>\n      <td>0</td>\n      <td>5</td>\n      <td>#sandy #newyork #hurricane #statueofliberty #u...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>262977091983785985</td>\n      <td>#nyc #hurricane http://t.co/Gv3QxZlq</td>\n      <td>0</td>\n      <td>2</td>\n      <td>#nyc #hurricane http://t.co/Gv3QxZlq</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>262989009930833920</td>\n      <td>robertosalibaba  god be with u brother #sandy ...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>robertosalibaba god be with u brother #sandy #...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>263129115207536640</td>\n      <td>#Crazy #Hurricane #Sandy http://t.co/0zrMsgvs</td>\n      <td>0</td>\n      <td>3</td>\n      <td>#crazy #hurricane #sandy http://t.co/0zrMsgvs</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>263091320871063552</td>\n      <td>#shark #newjersey #swim #sandy #hurricane  ...</td>\n      <td>1</td>\n      <td>5</td>\n      <td>#shark #newjersey #swim #sandy #hurricane http...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>262990978611286016</td>\n      <td>Good luck #ny #newyork #usa #hurricane #sandy ...</td>\n      <td>0</td>\n      <td>5</td>\n      <td>good luck #ny #newyork #usa #hurricane #sandy ...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>263070862977167360</td>\n      <td>Wow.... Fishing anyone? #hurricane #sandy http...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>wow ... fishing anyone ? #hurricane #sandy htt...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>263270378221228033</td>\n      <td>Well #howdy there #hurricane #sandy . Just wan...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>well #howdy there #hurricane #sandy . just wan...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>263229641999925249</td>\n      <td>Just known this bcs of #jason #chen updated th...</td>\n      <td>0</td>\n      <td>7</td>\n      <td>just known this bcs of #jason #chen updated th...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>263184498072645632</td>\n      <td>My thoughts and prayers go to all of the peopl...</td>\n      <td>0</td>\n      <td>10</td>\n      <td>my thought and prayer go to all of the people ...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>263001267926880258</td>\n      <td>Stay safe my New York family...#nyc #newyork #...</td>\n      <td>0</td>\n      <td>5</td>\n      <td>stay safe my new york family ... #nyc #newyork...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>263363592508829697</td>\n      <td>New York #hurricane #Sandy http://t.co/AnrR8u7t</td>\n      <td>0</td>\n      <td>2</td>\n      <td>new york #hurricane #sandy http://t.co/AnrR8u7t</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>263058558160076801</td>\n      <td>Probably the coolest pic of #hurricanesandy! #...</td>\n      <td>0</td>\n      <td>6</td>\n      <td>probably the coolest pic of #hurricanesandy ! ...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>263286294522777601</td>\n      <td>Crazy #sandy #hurricane images. Be glad we liv...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>crazy #sandy #hurricane image . be glad we liv...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>263010650517807104</td>\n      <td>My cousin sent this to me... :: Cleveland voic...</td>\n      <td>1</td>\n      <td>3</td>\n      <td>my cousin sent this to me ... :: cleveland voi...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>262976546527145984</td>\n      <td>We forget tomb unknown soldier is guard 24/736...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>we forget tomb unknown soldier is guard 24/736...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>262971979282395136</td>\n      <td>“@DarcyPhilip #new #york #hurricane #sandy htt...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>“ @darcyphilip #new #york #hurricane #sandy ht...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['tweetId', 'tweetText', 'emojis', 'hashtags', 'filteredTweetText']].head(25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Label Changes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_df['label'] = train_df['label'].apply(lambda label: 'fake' if label == 'humor' else label)\n",
    "test_df['label'] = test_df['label'].apply(lambda label: 'fake' if label == 'humor' else label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training set Changes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_df.drop_duplicates(subset=['filteredTweetText'], keep='first', inplace=True, ignore_index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction on Test Set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## With Feature Extraction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9051930758988016"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='char_wb', ngram_range=(5, 5))\n",
    "emojis_scalar = MinMaxScaler()\n",
    "hashtags_scalar = MinMaxScaler()\n",
    "model = MultinomialNB()\n",
    "\n",
    "X_train = hstack([\n",
    "            tfidf.fit_transform(train_df['filteredTweetText']),\n",
    "            emojis_scalar.fit_transform(train_df['emojis'].values.reshape(-1, 1)),\n",
    "            hashtags_scalar.fit_transform(train_df['hashtags'].values.reshape(-1, 1))\n",
    "        ])\n",
    "y_train = train_df['label']\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = hstack([\n",
    "            tfidf.transform(test_df['filteredTweetText']),\n",
    "            emojis_scalar.transform(test_df['emojis'].values.reshape(-1, 1)),\n",
    "            hashtags_scalar.transform(test_df['hashtags'].values.reshape(-1, 1))\n",
    "        ])\n",
    "y_test = test_df['label']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Without Feature Extraction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9051930758988016"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='char_wb', ngram_range=(5, 5))\n",
    "model = MultinomialNB()\n",
    "\n",
    "X_train = tfidf.fit_transform(train_df['filteredTweetText'])\n",
    "y_train = train_df['label']\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = tfidf.transform(test_df['filteredTweetText'])\n",
    "y_test = test_df['label']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}